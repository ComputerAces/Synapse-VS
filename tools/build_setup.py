import os
import re

def harvest_dependencies():
    """
    Scans the codebase for dynamic dependency requirements and generates a full requirements file.
    """
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    target_dirs = [
        os.path.join(root_dir, "synapse", "nodes"),
        os.path.join(root_dir, "plugins")
    ]
    
    min_reqs_path = os.path.join(root_dir, "setup", "requirements_min.txt")
    full_reqs_path = os.path.join(root_dir, "setup", "requirements_full.txt")
    
    # Regex to find: DependencyManager.ensure("package-name"
    # Matches single or double quotes, ignores whitespace.
    ensure_pattern = re.compile(r'DependencyManager\.ensure\(\s*["\']([^"\']+)["\']')
    
    discovered_packages = set()
    
    # 1. Scan for dependencies
    print(f"Scanning for dependencies in: {', '.join([os.path.relpath(d, root_dir) for d in target_dirs])}...")
    
    for target in target_dirs:
        if not os.path.exists(target):
            continue
            
        for root, _, files in os.walk(target):
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read()
                            matches = ensure_pattern.findall(content)
                            for match in matches:
                                discovered_packages.add(match)
                    except Exception as e:
                        print(f"  [WARN] Error reading {file_path}: {e}")

    # 2. Filter against requirements_min.txt
    core_packages = set()
    if os.path.exists(min_reqs_path):
        with open(min_reqs_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    # Basic normalization (strip version pins for comparison)
                    pkg = re.split(r'[=<>!]', line)[0].strip()
                    core_packages.add(pkg.lower())

    # 3. Process and Deduplicate
    # Normalize discovered list to lowercase for comparison with core list
    final_list = []
    for pkg in discovered_packages:
        # Check if the base name of the package is in core_packages
        clean_pkg = re.split(r'[=<>!]', pkg)[0].strip()
        if clean_pkg.lower() not in core_packages:
            final_list.append(pkg)
            
    # Include core packages in the "full" list as well, as it's intended to be a standalone full install
    # Actually User said: "filter out base engine dependencies" in the prompt text:
    # "cross-reference them against your core requirements_min.txt to filter out base engine dependencies."
    # BUT then says: "allows users to run a single pip install -r requirements_full.txt during setup to pre-load EVERY possible integration"
    # Usually a "Full" requirements file INCLUDES the minimum ones. 
    # However, I will follow the "filter out" instruction for the logic but maybe keep them for the file?
    # Actually, if I filter them out, requirements_full.txt is just the EXTRA stuff.
    # User said: "generate a clean, alphabetical requirements_full.txt. This allows users to run a single pip install -r requirements_full.txt ... to pre-load every possible integration"
    # This implies requirements_full.txt should be the CUMULATIVE list.
    
    # I'll include the core packages to make it truly "Full".
    if os.path.exists(min_reqs_path):
        with open(min_reqs_path, "r", encoding="utf-8") as f:
             for line in f:
                 line = line.strip()
                 if line and not line.startswith("#"):
                     if line not in final_list:
                         final_list.append(line)

    final_list = sorted(list(set(final_list)), key=lambda s: s.lower())

    # 4. Write to setup/requirements_full.txt
    os.makedirs(os.path.dirname(full_reqs_path), exist_ok=True)
    with open(full_reqs_path, "w", encoding="utf-8") as f:
        f.write("# Synapse VS - Complete Dependencies (Full Install)\n")
        f.write("# Generated by tools/build_setup.py\n\n")
        for pkg in final_list:
            f.write(f"{pkg}\n")
            
    print(f"\nSuccess! Generated {full_reqs_path}")
    print(f"Total unique dependencies: {len(final_list)}")
    print(f"Extra integrations found: {len(discovered_packages)}")

if __name__ == "__main__":
    harvest_dependencies()
